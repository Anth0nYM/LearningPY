import re
from nltk.tokenize import RegexpTokenizer
import nltk
print('USANDO A FUNÇÃO COUNT')
with open('corpus_teste.txt', 'r') as f:
    txt = f.read()
    tokenizer = RegexpTokenizer(r'\w+')
    texttok = tokenizer.tokenize(txt.lower())
    smile1 = texttok.count('lol')
    smile2 = texttok.count('ah')
    smile3 = texttok.count('eh')
    smile4 = texttok.count('hi')
    smile5 = texttok.count('kkkk')
    smile6 = texttok.count('hahaha')
    smile7 = texttok.count('rsrsrsrs')
    smile8 = texttok.count('ahuahuahua')
    expr1 = texttok.count('sim')
    expr2 = texttok.count('seria')
    print(smile1, '"lol" occurrences in the corpus')
    print(smile2, '"ah occurrences in the corpus')
    print(smile3, '"eh" occurrences in the corpus')
    print(smile4, '"hi" occurrences in the corpus')
    print(smile5, '"kkkk" occurrences in the corpus')
    print(smile6, '"hahaha" occurrences in the corpus')
    print(smile7, '"rsrsrsrs" occurrences in the corpus')
    print(smile8, '"ahuahuahua" occurrences in the corpus')
    print(expr1, '"sim" occurrences in the corpus')
    print(expr2, '"seria" occurrences in the corpus')
    print('USANDO REGEX')
    # Sempre faça buscas em minusculo
    txtbeta = 'kkkk Olha que coisa mais linda kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk lol, eh mais cheia de graça hahahaha. É ela menina hi quem vem e que passa, num doce balanço a caminho do mar '
    txtbetal = txtbeta.lower()
    laught1 = re.findall("lol|ah|eh|hi", txt.lower())
    #laught2 = re.findall('kkkk|^kkkk+k|haha|^haha+ha|rs|^rs+rs|hue|^hue+hue|aush|^aush+aush|ahu|^ahu+ahu',txt.lower())
    laught2 = re.findall('kkkk|haha|rs|hue|aush|ahu', txt.lower())
    expre1 = re.findall('sim', txt.lower())
    expre2 = re.findall('seria', txt.lower())
    print(len(laught1), len(laught2), len(expre1), len(expre2))
    # print(laught1,laught2,expre1,expre2)
